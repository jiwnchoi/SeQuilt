{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "env: ANYWIDGET_HMR=1\n",
      "env: ANYWIDGET_DEV=1\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env ANYWIDGET_HMR=1\n",
    "%env ANYWIDGET_DEV=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from scipy.cluster.hierarchy import dendrogram, fcluster, linkage\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import DistanceMetric\n",
    "\n",
    "from seq import Widget\n",
    "from seq.data.language import get_featured_ids, get_ids, get_tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"ajaykarthick/imdb-movie-reviews\")[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 2543.79it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "ids, tokens = get_ids(ds[\"review\"], tokenizer, max_tokens=32)\n",
    "featured_ids = get_featured_ids(ids, tokenizer, n_features=10)\n",
    "labels = [{\"id\": i, \"label\": tokenizer.id_to_token(i)} for i in featured_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed6d0c133824d49baaab0b235689eea",
       "version_major": 2,
       "version_minor": 1
      },
      "text/plain": [
       "Widget(labels=[{'id': 59, 'label': 'movie'}, {'id': 5, 'label': 'film'}, {'id': 30, 'label': 'one'}, {'id': 10…"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = Widget(\n",
    "  sequences=ids,\n",
    "  labels=labels,\n",
    ")\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_non_featured_sequences(\n",
    "  sequences: list[Any], label_ids: list[int]\n",
    ") -> np.ndarray:\n",
    "  sequences = np.array(sequences)\n",
    "  mask = np.isin(sequences, label_ids)\n",
    "  sequences = sequences * mask\n",
    "\n",
    "  return sequences[np.sum(mask, axis=1) > 0]\n",
    "\n",
    "\n",
    "labeld_sequences = mask_non_featured_sequences(ids, featured_ids)\n",
    "w.sequences = labeld_sequences.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x: np.ndarray) -> np.ndarray:\n",
    "  seq1 = x[:, np.newaxis, :]\n",
    "  seq2 = x[np.newaxis, :, :]\n",
    "  distances = seq1 != seq2\n",
    "  zero_distances = np.logical_and(seq1 == 0, seq2 == 0)\n",
    "  distances = np.maximum(distances, zero_distances)\n",
    "\n",
    "  distances = np.sum(distances, axis=2) / x.shape[1]\n",
    "  np.fill_diagonal(distances, 0)\n",
    "\n",
    "  return distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_sequences(sequences: list[Any]) -> np.ndarray:\n",
    "  sequences = np.array(sequences)\n",
    "  dist = distance(sequences)\n",
    "  # dist = DistanceMetric.get_metric(\"hamming\").pairwise(sequences)\n",
    "  dist = squareform(dist)\n",
    "  linkage_matrix = linkage(dist, method=\"average\")\n",
    "  dendrogram_data = dendrogram(linkage_matrix, no_plot=True)\n",
    "  order = dendrogram_data[\"leaves\"]\n",
    "  order = np.array(order)\n",
    "  return np.array(sequences)[order]\n",
    "\n",
    "\n",
    "clustered_sequences = cluster_sequences(labeld_sequences)\n",
    "w.sequences = clustered_sequences.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_sequences(sequences: list[Any], window_length: int) -> list[Any]:\n",
    "  unmasked = np.array(sequences.copy())\n",
    "  masks = []\n",
    "  for i in range(2 * window_length):\n",
    "    left = unmasked[i : -(2 * window_length - i), :]\n",
    "    right = unmasked[i + 1 : -(2 * window_length - i - 1) or None, :]\n",
    "    masks.append(left != right)\n",
    "\n",
    "  mask = np.logical_or.reduce(masks)\n",
    "  unmasked[window_length:-window_length, :][mask] = 0\n",
    "  return unmasked\n",
    "\n",
    "\n",
    "masked_sequences = mask_sequences(clustered_sequences, window_length=1)\n",
    "w.sequences = masked_sequences.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 32)\n"
     ]
    }
   ],
   "source": [
    "def filter_sequences(sequences: list[Any], filter_length: int) -> list[Any]:\n",
    "  sequences = np.array(sequences)\n",
    "  mask = np.sum((sequences != 0), axis=1) > filter_length\n",
    "\n",
    "  sequences = sequences[mask]\n",
    "\n",
    "  return sequences\n",
    "\n",
    "\n",
    "filtered_sequences = filter_sequences(masked_sequences, filter_length=2)\n",
    "print(filtered_sequences.shape)\n",
    "w.sequences = filtered_sequences.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_sequences(sequences: list[Any]):\n",
    "  sequences = np.array(sequences)\n",
    "  unique_sequences, count = np.unique(sequences, axis=0, return_counts=True)\n",
    "  dist_matrix = distance(unique_sequences)\n",
    "\n",
    "  G = nx.Graph()\n",
    "  for i in range(len(dist_matrix)):\n",
    "    for j in range(i + 1, len(dist_matrix)):\n",
    "      G.add_edge(i, j, weight=dist_matrix[i, j])\n",
    "\n",
    "  answer = nx.algorithms.approximation.christofides(G)\n",
    "  # answer = nx.algorithms.approximation.traveling_salesman_problem(G)\n",
    "  sorted_unique_sequences = unique_sequences[np.array(answer[:-1])]\n",
    "  sorted_original_sequences = []\n",
    "\n",
    "  for i, unique_sequence in enumerate(sorted_unique_sequences):\n",
    "    sorted_original_sequences.extend([unique_sequence] * count[i])\n",
    "\n",
    "  return np.array(sorted_original_sequences)\n",
    "\n",
    "\n",
    "sorted_sequences = sort_sequences(filtered_sequences)\n",
    "w.sequences = sorted_sequences.tolist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
