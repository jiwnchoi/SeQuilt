{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Any, Hashable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "class Chunk:\n",
    "  def __init__(self, subsequence=None, start=-1, end=-1, seq_indices=[]):\n",
    "    self.subsequence = subsequence\n",
    "    self.start = start\n",
    "    self.end = end\n",
    "    self.seq_indices: list[int] = seq_indices\n",
    "\n",
    "  def __eq__(self, other):\n",
    "    if not isinstance(other, Chunk):\n",
    "      return False\n",
    "    return (\n",
    "      self.start == other.start\n",
    "      and self.end == other.end\n",
    "      and np.array_equal(self.subsequence, other.subsequence)\n",
    "    )\n",
    "\n",
    "  def __hash__(self):\n",
    "    return hash((self.start, self.end, tuple(self.subsequence)))\n",
    "\n",
    "  def add_index(self, index: int):\n",
    "    self.seq_indices.append(index)\n",
    "\n",
    "  def __repr__(self) -> str:\n",
    "    return f\"Chunk({self.subsequence}, {self.start}, {self.end}, #{len(self.seq_indices)})\"\n",
    "\n",
    "\n",
    "class DB:\n",
    "  chunks: dict[Hashable, Chunk]\n",
    "  start_map: dict[int, list[Chunk]]\n",
    "  end_map: dict[int, list[Chunk]]\n",
    "  continue_map: dict[tuple[str, str], list[Chunk]]\n",
    "  seq_map: dict[tuple, list[Chunk]]\n",
    "\n",
    "  def __init__(self) -> None:\n",
    "    self.chunks = defaultdict(Chunk)\n",
    "    self.start_map = defaultdict(list)\n",
    "    self.end_map = defaultdict(list)\n",
    "    self.start_end_map = defaultdict(list)\n",
    "    self.continue_map = defaultdict(list)\n",
    "    self.seq_map = defaultdict(list)\n",
    "    self.length_map = defaultdict(list)\n",
    "\n",
    "  def __getitem__(self, key: Hashable) -> Chunk | None:\n",
    "    return self.chunks.get(key, None)\n",
    "\n",
    "  def add(self, chunk: Chunk):\n",
    "    if chunk in self.chunks:\n",
    "      self.chunks[chunk].seq_indices.extend(chunk.seq_indices)\n",
    "    else:\n",
    "      self.chunks[chunk] = chunk\n",
    "      self.start_map[chunk.start].append(chunk)\n",
    "      self.end_map[chunk.end].append(chunk)\n",
    "      self.start_end_map[(chunk.start, chunk.end)].append(chunk)\n",
    "      self.seq_map[tuple(chunk.subsequence)].append(chunk)\n",
    "      self.length_map[len(chunk.subsequence)].append(chunk)\n",
    "      for i in range(len(chunk.subsequence)):\n",
    "        if i > 1:\n",
    "          self.continue_map[\n",
    "            (f\"{chunk.start}*\", tuple(chunk.subsequence[:i]))\n",
    "          ].append(chunk)\n",
    "        if i < len(chunk.subsequence) - 2:\n",
    "          self.continue_map[\n",
    "            (f\"*{chunk.end}\", tuple(chunk.subsequence[i + 1 :]))\n",
    "          ].append(chunk)\n",
    "\n",
    "  def get_candidate(self, chunk: Chunk) -> list[Chunk]:\n",
    "    candidates = {\n",
    "      *self.get(start=chunk.start, sub_sequences=chunk.subsequence),\n",
    "      *self.get(end=chunk.end, sub_sequences=chunk.subsequence),\n",
    "    }\n",
    "    for i in range(1, len(chunk.subsequence) - 1):\n",
    "      left = self.get(\n",
    "        start=chunk.start + i,\n",
    "        end=chunk.end,\n",
    "        sub_sequences=chunk.subsequence[i:],\n",
    "      )\n",
    "      left_continue = self.get(\n",
    "        start=chunk.start + i, sub_sequences=chunk.subsequence[i:]\n",
    "      )\n",
    "      right = self.get(\n",
    "        start=chunk.start,\n",
    "        end=chunk.end - i,\n",
    "        sub_sequences=chunk.subsequence[:-i],\n",
    "      )\n",
    "      right_continue = self.get(\n",
    "        end=chunk.end - i, sub_sequences=chunk.subsequence[:-i]\n",
    "      )\n",
    "      candidates.update(set(left + left_continue + right + right_continue))\n",
    "\n",
    "      if len(candidates) > 1:\n",
    "        break\n",
    "\n",
    "    return sorted(\n",
    "      list(candidates),\n",
    "      key=lambda x: len(x.subsequence) * 100000 + len(x.seq_indices),\n",
    "      reverse=True,\n",
    "    )\n",
    "\n",
    "  def get(\n",
    "    self, start: int = -1, end: int = -1, sub_sequences=None\n",
    "  ) -> list[Chunk]:\n",
    "    if sub_sequences is None:\n",
    "      if start == -1 and end == -1:\n",
    "        raise ValueError(\"Either start, end or sub_sequences must be provided\")\n",
    "      elif start == -1:\n",
    "        return self.end_map[end]\n",
    "      elif end == -1:\n",
    "        return self.start_map[start]\n",
    "      else:\n",
    "        return self.start_end_map[(start, end)]\n",
    "\n",
    "    else:\n",
    "      if start == -1 and end == -1:\n",
    "        return self.seq_map[tuple(sub_sequences)]\n",
    "      elif start == -1:\n",
    "        return self.continue_map[(f\"*{end}\", tuple(sub_sequences))]\n",
    "      elif end == -1:\n",
    "        return self.continue_map[(f\"{start}*\", tuple(sub_sequences))]\n",
    "      else:\n",
    "        c = self.chunks.get(\n",
    "          Chunk(\n",
    "            start=start, end=end, subsequence=sub_sequences, seq_indices=[]\n",
    "          ),\n",
    "          None,\n",
    "        )\n",
    "        return [c] if c else []\n",
    "\n",
    "  def get_random(self):\n",
    "    return np.random.choice(list(self.chunks.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_chunks(\n",
    "  data: np.ndarray,\n",
    "  threshold: int = 10,\n",
    "  max_chunk_length: int = 6,\n",
    "):\n",
    "  n_sequences, n_length = data.shape\n",
    "  db = DB()\n",
    "\n",
    "  for chunk_length in range(max_chunk_length, 0, -1):\n",
    "    # Create a view of all possible chunks of the current length\n",
    "    chunk_view = np.lib.stride_tricks.sliding_window_view(\n",
    "      data, (1, chunk_length)\n",
    "    ).reshape(n_sequences, n_length - chunk_length + 1, chunk_length)\n",
    "\n",
    "    # Hash each chunk\n",
    "    chunk_hashes = np.apply_along_axis(lambda x: hash(tuple(x)), 2, chunk_view)\n",
    "\n",
    "    # Find unique chunks and their counts\n",
    "    unique_chunks, indices, counts = np.unique(\n",
    "      chunk_hashes, return_inverse=True, return_counts=True, axis=None\n",
    "    )\n",
    "\n",
    "    # Process only chunks that meet the threshold\n",
    "    mask = counts >= threshold\n",
    "    for chunk_hash in unique_chunks[mask]:\n",
    "      # Get the indices of sequences containing this chunk\n",
    "      seq_indices = np.where(chunk_hashes == chunk_hash)[0]\n",
    "\n",
    "      # Get the start position of the chunk\n",
    "      start = np.where(chunk_hashes == chunk_hash)[1][0]\n",
    "      end = start + chunk_length\n",
    "\n",
    "      # Get the actual chunk sequence\n",
    "      chunk_seq = chunk_view[seq_indices[0], start]\n",
    "\n",
    "      db.add(\n",
    "        Chunk(\n",
    "          subsequence=chunk_seq,\n",
    "          start=int(start),\n",
    "          end=int(end),\n",
    "          seq_indices=seq_indices,\n",
    "        )\n",
    "      )\n",
    "\n",
    "  return db\n",
    "\n",
    "\n",
    "# Example usage\n",
    "n_sequences = 100_000\n",
    "n_length = 32\n",
    "threshold = int(0.05 * n_sequences)\n",
    "max_chunk_length = 6\n",
    "data = np.random.randint(1, 5, (n_sequences, n_length))\n",
    "db = find_chunks(data, threshold, max_chunk_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([4, 3, 2, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.length_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = sorted(\n",
    "  list(db.chunks.values()),\n",
    "  key=lambda x: len(x.subsequence) * 100000 + len(x.seq_indices),\n",
    "  reverse=True,\n",
    ")\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "processed = set()\n",
    "\n",
    "paths = []\n",
    "\n",
    "\n",
    "def get_candi(chunk: Chunk, processed, s, e, is_left=True):\n",
    "  if is_left:\n",
    "    return [\n",
    "      c for c in db.get_candidate(chunk) if c not in processed and c.end > s\n",
    "    ]\n",
    "  else:\n",
    "    return [\n",
    "      c for c in db.get_candidate(chunk) if c not in processed and c.start < e\n",
    "    ]\n",
    "\n",
    "\n",
    "for node in nodes:\n",
    "  deq = deque([node])\n",
    "  s = node.start\n",
    "  e = node.end\n",
    "\n",
    "  processed.add(node)\n",
    "\n",
    "  left_candi = get_candi(deq[0], processed, s, e, is_left=True)\n",
    "  right_candi = get_candi(deq[-1], processed, s, e, is_left=False)\n",
    "\n",
    "  while len(left_candi) > 0 or len(right_candi) > 0:\n",
    "    if len(left_candi) > 0 and left_candi[0].end > s:\n",
    "      deq.appendleft(left_candi[0])\n",
    "      processed.add(left_candi[0])\n",
    "    if len(right_candi) > 0 and right_candi[0].start < e:\n",
    "      deq.append(right_candi[0])\n",
    "      processed.add(right_candi[0])\n",
    "\n",
    "    left_candi = get_candi(deq[0], processed, s, e, is_left=True)\n",
    "    right_candi = get_candi(deq[-1], processed, s, e, is_left=False)\n",
    "  paths.append(deq)\n",
    "\n",
    "paths = sorted(\n",
    "  [p for p in paths],\n",
    "  key=lambda x: sum([len(c.seq_indices) for c in x]),\n",
    "  reverse=True,\n",
    ")\n",
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000000, 32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canvas = np.zeros((data.shape[0] * 10000, data.shape[1]))\n",
    "canvas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing paths: 100%|██████████| 340/340 [01:33<00:00,  3.63it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_shape(path: list[Chunk]) -> np.ndarray:\n",
    "  total_length = sum(len(chunk.seq_indices) for chunk in path)\n",
    "  shape = np.zeros((total_length, canvas.shape[1]))\n",
    "  current_index = 0\n",
    "  for chunk in path:\n",
    "    chunk_length = len(chunk.seq_indices)\n",
    "    shape[\n",
    "      current_index : current_index + chunk_length, chunk.start : chunk.end\n",
    "    ] = chunk.subsequence\n",
    "    current_index += chunk_length\n",
    "  return shape\n",
    "\n",
    "\n",
    "def find_drawable_position(canvas: np.ndarray, shape: np.ndarray) -> int:\n",
    "  if canvas.shape[1] != shape.shape[1]:\n",
    "    raise ValueError(\"Canvas and shape must have the same width\")\n",
    "\n",
    "  canvas_height, shape_height = canvas.shape[0], shape.shape[0]\n",
    "  max_start = canvas_height - shape_height + 1\n",
    "\n",
    "  for i in range(0, max_start, max(threshold, int(shape_height / 10))):\n",
    "    sub_canvas = canvas[i : i + shape_height]\n",
    "    target = shape != 0\n",
    "    if np.all(sub_canvas[target] == 0):\n",
    "      return i\n",
    "\n",
    "  return -1  # No drawable position found\n",
    "\n",
    "\n",
    "canvas = np.zeros((data.shape[0] * 100, data.shape[1]))\n",
    "positions = []\n",
    "for path in tqdm(paths, desc=\"Processing paths\"):\n",
    "  shape = get_shape(path)\n",
    "  position = find_drawable_position(canvas, shape)\n",
    "  positions.append(position)\n",
    "  if position != -1:\n",
    "    canvas[position : position + shape.shape[0]][shape != 0] = shape[shape != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000000, 32)\n",
      "(4133470, 32)\n"
     ]
    }
   ],
   "source": [
    "filtered_canvas = canvas[~np.all(canvas == 0, axis=1)]\n",
    "print(canvas.shape)\n",
    "print(filtered_canvas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.4872084925014576)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(filtered_canvas != 0) / np.prod(filtered_canvas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_row(row: np.ndarray):\n",
    "  print(\"\".join([f\"{int(x)}\" if x != 0 else \" \" for x in row]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "prev_row = np.zeros(canvas.shape[1])\n",
    "for i in range(0, canvas.shape[0]):\n",
    "  row = canvas[i]\n",
    "  if not np.array_equal(row, prev_row) and not np.sum(row) == 0:\n",
    "    rows.append(row)\n",
    "    prev_row = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1040"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82886"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(c.seq_indices) for c in paths[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3\n"
     ]
    }
   ],
   "source": [
    "d = deque([1, 2, 3])\n",
    "print(d[0], d[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(Chunk([0 2 1 2], 7, 11, #123), Chunk([2 1 2 2], 8, 12, #140)), (Chunk([1 2 2 2], 9, 13, #107), Chunk([2 1 2 2], 8, 12, #140)), (Chunk([2 1 2], 8, 11, #504), Chunk([2 1 2 2], 8, 12, #140)), (Chunk([1 2 2], 9, 12, #489), Chunk([2 1 2 2], 8, 12, #140))]\n"
     ]
    }
   ],
   "source": [
    "while len(candi):\n",
    "  org_candi = candi.copy()\n",
    "  new_candi = [db.get_candidate(c) for c in candi]\n",
    "  edges = [(org_candi[i], c[0]) for i, c in enumerate(new_candi) if len(c)]\n",
    "  print(edges)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk([2 3 3 0 1 0], 10, 16, #60)\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "c = db.get_random()\n",
    "print(c)\n",
    "print(db.get(start=c.start, sub_sequences=c.subsequence))\n",
    "print(db.get(end=c.end, sub_sequences=c.subsequence))\n",
    "print(db.get(start=c.start, end=c.end - 1, sub_sequences=c.subsequence[:-1]))\n",
    "print(db.get(start=c.start + 1, end=c.end, sub_sequences=c.subsequence[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Chunk([3 3 1], 1, 4, #2345), Chunk([0 2 1], 1, 4, #2376)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get(1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk([0], 1, 2, #40120)\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print((db.get(1, 2)[0]))\n",
    "print(db.get(1, 2, [2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Chunk([3, 0, 2], 1, 4, #2298), Chunk([3, 1, 0], 1, 4, #2290), Chunk([1, 1, 0], 1, 4, #2351), Chunk([1, 3, 0], 1, 4, #2374), Chunk([1, 3, 2], 1, 4, #2331)]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(db.get(1, 4))\n",
    "print(db.get(0, 5, [1, 3, 3, 1, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get(14, 18, (2, 1, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1429464707349485113"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash((1, 2, (1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1429464707349485113"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash((1, 2, (1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
